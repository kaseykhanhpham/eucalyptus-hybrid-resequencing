#!/bin/bash
#SBATCH --account=soltis
#SBATCH --qos=soltis
#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=rl_trn_g
#SBATCH --mail-type=ALL
#SBATCH --mail-user=kasey.pham@ufl.edu
#SBATCH --mem=100gb
#SBATCH --time=4-00:00:00
#SBATCH --cpus-per-task=8
#SBATCH --nodes=1
#SBATCH --output=relernn_train_glob_%j.out
#SBATCH --error=relernn_train_glob_%j.err

module load relernn/1.0.0
module load cuda/12.2.2
declare -a VCFLIST=(Chr01 Chr02 Chr03 Chr04 Chr05 Chr06 Chr07 Chr08 Chr09 Chr10 Chr11)
export XLA_FLAGS=--xla_gpu_cuda_data_dir=/apps/compilers/cuda/12.2.2

for NAME in "${VCFLIST[@]}"
do
    ReLERNN_TRAIN -d "$NAME" -t 8
done